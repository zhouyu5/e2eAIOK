# Copyright (C) 2023 Intel Corporation
# SPDX-License-Identifier: MIT
# Downloaded from https://github.com/intel/graph-neural-networks-and-analytics
env:
  num_node: 1
  node_ips: #pls make sure that the ip doesn't contain space in the end
    - localhost
  tmp_path: ../graph_data/
  #tmp_path used to save model, embeddings, partitions...
  data_path: ../graph_data/sym_recsys_hetero_CSVDatasets
  in_data_filename: edges_train.csv.gz
  #data_path should contain processed_data.csv
  out_path: ../graph_data/
  #out_path will contain the output csv with the tabular data and new node embeddings
  config_path: ./configs
  #for single node docker exec paths need to be on /localdisk (or NFS with full permissions)
  #for distributed exec paths need to be on NFS along with code repo
  bare_metal: True
  #bare_metal=False means run using docker container
  train_config_file: model-training.yaml
  tabular2graph_config_file: recsys2graph.yaml

#first time run all stages but later you can set stages to False to run with prior results
#i.e skip building graph and partitions to save time and jump directly to training
single:
  build_graph: False
  #build_graph stage generates CSVDataset files for DGL to ingest data as graph
  gnn_training: True
  map_save: True
  #map_save stage performs the mapping of the computed node embeddings to the input tabular data file

distributed:
  build_graph: False
  partition_graph: False
  #partition_graph stages uses random partition algorithm to generate "num_parts" subgraphs for distributed training
  gnn_training: True
  map_save: False
  num_parts: 2
  #during training num_parts should match the env_num_nodes. If running partitioning stage by itself you can modify the number
  #(i,e if you want to do multiple graph pre-partitioning before starting the training runs)
  
graph:
  #provide a name for the graph
  CSVDataset_name: sym_recsys_hetero_CSVDatasets
  name: recsys_full_homo

